{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "import regex as re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= new_df['selftext']\n",
    "y= new_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    How come most Star Wars fans completly turn ar...\n",
       "1    The latest 2 episodes of the clone wars are so...\n",
       "2    So, to start it off i gotta tell that not just...\n",
       "3    In the bar on Kijimi there is a character call...\n",
       "4    At the beginning of the duel between Ahsoka an...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.515179\n",
       "1    0.484821\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/upasanamahanta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import stopwords.\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'done', 'most', 'i', 'every', 'alone', 'thick', 'thru', 'side', 'other', 'if', 'former', 'two', 'until', 'onto', 'only', 'someone', 'should', 'yourselves', 'around', 'whatever', 'down', 'back', 'seeming', 'itself', 'out', 'full', 'wherein', 'also', 'will', 'do', 'beyond', 'have', 'him', 'neither', 'whole', 'here', 'might', 'she', 'yet', 'below', 'meanwhile', 'its', 'three', 'with', 'next', 'too', 'what', 'none', 'become', 'one', 'throughout', 'call', 'otherwise', 'rather', 'though', 'somehow', 'then', 'we', 'formerly', 'as', 'amongst', 'more', 'their', 'together', 'toward', 'hereupon', 'myself', 'anyone', 'indeed', 'beside', 'towards', 'me', 'sixty', 're', 'name', 'latterly', 'whether', 'empty', 'whereupon', 'however', 'twenty', 'us', 'something', 'whereafter', 'either', 'about', 'and', 'ltd', 'on', 'first', 'less', 'many', 'others', 'elsewhere', 'cant', 'besides', 'no', 'always', 'inc', 'front', 'anywhere', 'top', 'there', 'under', 'de', 'thus', 'much', 'themselves', 'among', 'upon', 'another', 'further', 'ourselves', 'becomes', 'becoming', 'between', 'few', 'was', 'thereafter', 'both', 'eg', 'am', 'found', 'whereas', 'yours', 'detail', 'anyway', 'than', 'whose', 'ie', 'or', 'how', 'herein', 'mine', 'sometimes', 'while', 'again', 'thence', 'due', 'my', 'ever', 'serious', 'her', 'since', 'hers', 'beforehand', 'whenever', 'see', 'fill', 'the', 'therefore', 'this', 'please', 'now', 'not', 'sometime', 'via', 'seems', 'these', 'whereby', 'when', 'against', 'made', 'five', 'amount', 'that', 'whence', 'third', 'system', 'hundred', 'therein', 'a', 'are', 'put', 'seem', 'being', 'along', 'without', 'of', 'during', 'everywhere', 'four', 'part', 'hence', 'by', 'himself', 'thin', 'which', 'move', 'noone', 'else', 'is', 'across', 'moreover', 'amoungst', 'forty', 'were', 'whither', 'everyone', 'your', 'because', 'they', 'show', 'who', 'anyhow', 'never', 'describe', 'any', 'eleven', 'mostly', 'etc', 'wherever', 'although', 'whom', 'co', 'why', 'be', 'last', 'sincere', 'afterwards', 'give', 'had', 'own', 'nowhere', 'even', 'almost', 'interest', 'nine', 'namely', 'except', 'he', 'our', 'before', 'once', 'con', 'twelve', 'bill', 'six', 'nothing', 'yourself', 'thereupon', 'fire', 'to', 'over', 'must', 'nor', 'nobody', 'bottom', 'in', 'un', 'fifteen', 'some', 'nevertheless', 'from', 'keep', 'same', 'each', 'after', 'within', 'you', 'couldnt', 'everything', 'fifty', 'at', 'through', 'latter', 'least', 'hereby', 'anything', 'up', 'very', 'mill', 'ten', 'seemed', 'hereafter', 'above', 'whoever', 'became', 'so', 'find', 'where', 'get', 'could', 'behind', 'into', 'would', 'often', 'thereby', 'an', 'eight', 'per', 'well', 'those', 'herself', 'take', 'them', 'for', 'enough', 'hasnt', 'all', 'but', 'it', 'has', 'his', 'ours', 'perhaps', 'off', 'such', 'may', 'been', 'cannot', 'somewhere', 'cry', 'go', 'can', 'several', 'already', 'still'})\n"
     ]
    }
   ],
   "source": [
    "print(CountVectorizer(stop_words='english').get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'done', 'most', 'i', 'every', 'alone', 'thick', 'thru', 'side', 'other', 'if', 'former', 'two', 'until', 'onto', 'only', 'someone', 'should', 'yourselves', 'around', 'whatever', 'down', 'back', 'seeming', 'itself', 'out', 'full', 'wherein', 'also', 'will', 'do', 'beyond', 'have', 'him', 'neither', 'whole', 'here', 'might', 'she', 'yet', 'below', 'meanwhile', 'its', 'three', 'with', 'next', 'too', 'what', 'none', 'become', 'one', 'throughout', 'call', 'otherwise', 'rather', 'though', 'somehow', 'then', 'we', 'formerly', 'as', 'amongst', 'more', 'their', 'together', 'toward', 'hereupon', 'myself', 'anyone', 'indeed', 'beside', 'towards', 'me', 'sixty', 're', 'name', 'latterly', 'whether', 'empty', 'whereupon', 'however', 'twenty', 'us', 'something', 'whereafter', 'either', 'about', 'and', 'ltd', 'on', 'first', 'less', 'many', 'others', 'elsewhere', 'cant', 'besides', 'no', 'always', 'inc', 'front', 'anywhere', 'top', 'there', 'under', 'de', 'thus', 'much', 'themselves', 'among', 'upon', 'another', 'further', 'ourselves', 'becomes', 'becoming', 'between', 'few', 'was', 'thereafter', 'both', 'eg', 'am', 'found', 'whereas', 'yours', 'detail', 'anyway', 'than', 'whose', 'ie', 'or', 'how', 'herein', 'mine', 'sometimes', 'while', 'again', 'thence', 'due', 'my', 'ever', 'serious', 'her', 'since', 'hers', 'beforehand', 'whenever', 'see', 'fill', 'the', 'therefore', 'this', 'please', 'now', 'not', 'sometime', 'via', 'seems', 'these', 'whereby', 'when', 'against', 'made', 'five', 'amount', 'that', 'whence', 'third', 'system', 'hundred', 'therein', 'a', 'are', 'put', 'seem', 'being', 'along', 'without', 'of', 'during', 'everywhere', 'four', 'part', 'hence', 'by', 'himself', 'thin', 'which', 'move', 'noone', 'else', 'is', 'across', 'moreover', 'amoungst', 'forty', 'were', 'whither', 'everyone', 'your', 'because', 'they', 'show', 'who', 'anyhow', 'never', 'describe', 'any', 'eleven', 'mostly', 'etc', 'wherever', 'although', 'whom', 'co', 'why', 'be', 'last', 'sincere', 'afterwards', 'give', 'had', 'own', 'nowhere', 'even', 'almost', 'interest', 'nine', 'namely', 'except', 'he', 'our', 'before', 'once', 'con', 'twelve', 'bill', 'six', 'nothing', 'yourself', 'thereupon', 'fire', 'to', 'over', 'must', 'nor', 'nobody', 'bottom', 'in', 'un', 'fifteen', 'some', 'nevertheless', 'from', 'keep', 'same', 'each', 'after', 'within', 'you', 'couldnt', 'everything', 'fifty', 'at', 'through', 'latter', 'least', 'hereby', 'anything', 'up', 'very', 'mill', 'ten', 'seemed', 'hereafter', 'above', 'whoever', 'became', 'so', 'find', 'where', 'get', 'could', 'behind', 'into', 'would', 'often', 'thereby', 'an', 'eight', 'per', 'well', 'those', 'herself', 'take', 'them', 'for', 'enough', 'hasnt', 'all', 'but', 'it', 'has', 'his', 'ours', 'perhaps', 'off', 'such', 'may', 'been', 'cannot', 'somewhere', 'cry', 'go', 'can', 'several', 'already', 'still'})\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Let's look at sklearn's stopwords.\n",
    "print(CountVectorizer(stop_words = 'english').get_stop_words())\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670     1\n",
       "1033    1\n",
       "67      0\n",
       "903     1\n",
       "1082    1\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670     I'm guessing it is... and I had to read it a n...\n",
       "1033    Hello !\\n\\nI am a huge fan of Star trek since ...\n",
       "67       I think we can all agree that neither timelin...\n",
       "903     And one question was, â€œwhy were the synths so ...\n",
       "1082    First, before people think I'm going to basele...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selftext_to_words(raw_selftext):\n",
    "      \n",
    "    # 1. Remove HTML.\n",
    "    selftext_text = BeautifulSoup(raw_selftext).get_text()\n",
    "    \n",
    "    # 2. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", selftext_text)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # a list, so convert the stopwords to a set.\n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    # 5. Remove stopwords.\n",
    "    meaningful_words = [w for w in words if w not in stops]\n",
    "    \n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(meaningful_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1087 selftext.\n"
     ]
    }
   ],
   "source": [
    "#Get the number of selftext based on the dataframe size.\n",
    "total_selftext = new_df.shape[0]\n",
    "print(f'There are {total_selftext} selftext.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set post selftext...\n",
      "selftext 100 of 1087.\n",
      "selftext 200 of 1087.\n",
      "selftext 300 of 1087.\n",
      "selftext 400 of 1087.\n",
      "selftext 500 of 1087.\n",
      "selftext 600 of 1087.\n",
      "selftext 700 of 1087.\n",
      "Cleaning and parsing the testing set post selftext...\n",
      "selftext 100 of 1087.\n",
      "selftext 200 of 1087.\n",
      "selftext 300 of 1087.\n"
     ]
    }
   ],
   "source": [
    " #Initialize an empty list to hold the clean selftext.\n",
    "clean_train_selftexts = []\n",
    "clean_test_selftexts = []\n",
    "\n",
    "print(\"Cleaning and parsing the training set post selftext...\")\n",
    "\n",
    "# Instantiate counter.\n",
    "j = 0\n",
    "\n",
    "# For every review in our training set...\n",
    "for train_selftext in X_train:\n",
    "    \n",
    "    # Convert text to words, then append to clean_train_selftext.\n",
    "    clean_train_selftexts.append(selftext_to_words(train_selftext))\n",
    "    \n",
    "    # If the index is divisible by 1000, print a message.\n",
    "    if (j + 1) % 100 == 0:\n",
    "        print(f'selftext {j + 1} of {total_selftext}.')\n",
    "    \n",
    "    j += 1\n",
    "\n",
    "# Let's do the same for our testing set.\n",
    "print(\"Cleaning and parsing the testing set post selftext...\")\n",
    "\n",
    "# Instantiate counter.\n",
    "j = 0\n",
    "\n",
    "# For every review in our training set...\n",
    "for test_selftext in X_test:\n",
    "    \n",
    "    # Convert text to words, then append to clean_train_selftext.\n",
    "    clean_test_selftexts.append(selftext_to_words(test_selftext))\n",
    "    \n",
    "    # If the index is divisible by 1000, print a message.\n",
    "    if (j + 1) % 100 == 0:\n",
    "        print(f'selftext {j + 1} of {total_selftext}.')\n",
    "    \n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the \"CountVectorizer\" object, which is sklearn's\n",
    "# bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_selftexts)\n",
    "test_data_features = vectorizer.transform(clean_test_selftexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(728, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aayla', 'abandoned', 'abandoning', 'abducted', 'abilities', 'ability', 'able', 'aboard', 'abrams', 'abruptly', 'absolute', 'absolutely', 'absurd', 'abusive', 'academy', 'accent', 'accept', 'acceptable', 'acceptance', 'accepted', 'accepting', 'access', 'accessible', 'accident', 'accidentally', 'accomplish', 'accomplished', 'according', 'achieve', 'across', 'act', 'acted', 'acting', 'action', 'actions', 'activate', 'active', 'actively', 'actor', 'actors', 'actress', 'acts', 'actual', 'actually', 'adam', 'adapt', 'add', 'added', 'adding', 'addition', 'additional', 'adds', 'adi', 'admiral', 'admit', 'admittedly', 'admonition', 'adopted', 'adoptive', 'ads', 'adult', 'adults', 'advance', 'advanced', 'advancements', 'advances', 'adventure', 'adventures', 'advice', 'aesthetic', 'af', 'affect', 'affects', 'afford', 'afraid', 'aftermath', 'afterwards', 'age', 'aged', 'agen', 'aggressive', 'agnes', 'ago', 'agree', 'agreed', 'agrees', 'ahead', 'ahsoka', 'ai', 'aim', 'aiming', 'air', 'aired', 'airing', 'aka', 'albeit', 'alert', 'alien', 'aliens', 'alike', 'alive', 'allegiance', 'alliance', 'allie', 'allies', 'allow', 'allowed', 'allowing', 'almost', 'alone', 'along', 'alongside', 'alot', 'alpha', 'already', 'alright', 'also', 'altered', 'alternate', 'although', 'always', 'amazing', 'amazingly', 'ambiguous', 'america', 'american', 'among', 'amongst', 'amount', 'amp', 'anakin', 'analogy', 'analysis', 'ancient', 'android', 'androids', 'anger', 'angle', 'angry', 'angrydont', 'anh', 'animals', 'animated', 'animation', 'anniversary', 'announced', 'annoyed', 'annoying', 'another', 'answer', 'answered', 'answers', 'antagonist', 'antagonists', 'anthony', 'anti', 'anxiety', 'anybody', 'anymore', 'anyone', 'anything', 'anytime', 'anyway', 'anyways', 'anywhere', 'aotc', 'ap', 'apart', 'aphra', 'apologize', 'apparent', 'apparently', 'appeal', 'appeals', 'appear', 'appearance', 'appearances', 'appeared', 'appears', 'apple', 'applies', 'appreciate', 'appreciated', 'appreciation', 'apprentice', 'approach', 'approached', 'appropriate', 'approx', 'april', 'ar', 'arc', 'archer', 'arcs', 'area', 'areas', 'arena', 'arent', 'arguably', 'argue', 'argued', 'arguing', 'argument', 'arguments', 'arm', 'armageddon', 'armor', 'arms', 'army', 'around', 'arrive', 'arrives', 'art', 'article', 'artifact', 'artificial', 'arts', 'asajj', 'ashoka', 'aside', 'ask', 'asked', 'asking', 'asks', 'asoka', 'aspect', 'aspects', 'ass', 'assasination', 'assassin', 'asses', 'asset', 'asshole', 'assigned', 'assignment', 'assimilated', 'assimilating', 'associated', 'association', 'assume', 'assumed', 'assuming', 'assumption', 'assumptions', 'astronauts', 'atlan', 'atleast', 'atmosphere', 'attached', 'attachment', 'attachments', 'attack', 'attacked', 'attacks', 'attempt', 'attempted', 'attempts', 'attention', 'attitude', 'attribute', 'auberjonois', 'audience', 'audiences', 'audio', 'august', 'aunt', 'aurra', 'australia', 'author', 'autism', 'autistic', 'automated', 'automatically', 'available', 'avenge', 'avengers', 'average', 'averages', 'avery', 'avoid', 'avoided', 'avoiding', 'awake', 'awakening', 'awakens', 'aware', 'away', 'awesome', 'awesomeness', 'awful', 'awfully', 'awkward', 'ay', 'babel', 'baby', 'back', 'background', 'backing', 'backs', 'backstory', 'backup', 'backwards', 'bad', 'badass', 'badda', 'baddest', 'badly', 'baffled', 'bag', 'bail', 'bajor', 'bajoran', 'balance', 'balanced', 'bald', 'balls', 'ballsy', 'bam', 'ban', 'band', 'bane', 'banes', 'bang', 'banks', 'banter', 'bar', 'barclay', 'bare', 'barely', 'barring', 'barris', 'barriss', 'base', 'baseball', 'based', 'basement', 'bashir', 'basic', 'basically', 'basis', 'bat', 'batch', 'battle', 'battlefront', 'battles', 'bay', 'bb', 'bby', 'bc', 'beach', 'beacon', 'beam', 'beamed', 'beaming', 'beams', 'beans', 'bear', 'beast', 'beat', 'beaten', 'beating', 'beats', 'beautiful', 'beautifully', 'beauty', 'became', 'becket', 'become', 'becomes', 'becoming', 'bed', 'beeing', 'beg', 'began', 'begin', 'beginning', 'begins', 'begun', 'behave', 'behind', 'beings', 'belief', 'beliefs', 'believable', 'believe', 'believed', 'believes', 'believing', 'belong', 'belonged', 'belonging', 'beloved', 'belt', 'belts', 'ben', 'bend', 'beneath', 'benefit', 'benefits', 'benjamin', 'berated', 'besides', 'best', 'besting', 'bet', 'beta', 'betazoids', 'betray', 'betrayal', 'betrayed', 'betrays', 'better', 'beverly', 'beyond', 'big', 'bigger', 'biggest', 'bigotry', 'billaba', 'billie', 'billion', 'billions', 'binary', 'binge', 'binged', 'binging', 'bingo', 'biological', 'bird', 'birth', 'birthday', 'bit', 'bite', 'bits', 'bitter', 'bizarre', 'black', 'blade', 'blades', 'blah', 'blame', 'blaming', 'bland', 'blank', 'blast', 'blaster', 'blasters', 'bleed', 'bleeding', 'blend', 'blessing', 'blew', 'bloc', 'block', 'blockbuster', 'blocked', 'blocking', 'blocks', 'blonde', 'blood', 'bloodline', 'bloody', 'blow', 'blown', 'blows', 'blu', 'blue', 'bo', 'board', 'boards', 'boba', 'bodies', 'body', 'bold', 'bolla', 'bolts', 'bomb', 'bombing', 'bombs', 'bond', 'bones', 'bonus', 'book', 'books', 'boom', 'boot', 'booted', 'booty', 'border', 'bored', 'borg', 'boring', 'born', 'borrow', 'bospet', 'boss', 'bother', 'bothers', 'bottle', 'bought', 'bound', 'boundaries', 'bounty', 'box', 'boxset', 'boy', 'boys', 'brain', 'brainwashed', 'brand', 'bravery', 'break', 'breaking', 'breaks', 'brent', 'brian', 'brick', 'bridge', 'bridger', 'brief', 'briefly', 'brien', 'brilliant', 'bring', 'bringing', 'brings', 'bro', 'broke', 'broken', 'broom', 'brother', 'brothers', 'brought', 'bruce', 'brutal', 'brutally', 'bsg', 'btw', 'bucket', 'bucks', 'budget', 'bugs', 'build', 'building', 'built', 'bulkheads', 'bullshit', 'bullying', 'bummed', 'bunch', 'burden', 'burdened', 'bureaucracy', 'buried', 'burn', 'burnham', 'burning', 'business', 'busy', 'buy', 'buying', 'caedus', 'cake', 'cal', 'calendar', 'call', 'called', 'calling', 'calls', 'calm', 'came', 'cameo', 'camera', 'canceled', 'cancelled', 'cannon', 'cannot', 'canon', 'canonical', 'cant', 'cantina', 'capable', 'capitalism', 'captain', 'captains', 'capture', 'captured', 'card', 'cardassia', 'cardassian', 'cardassians', 'cards', 'care', 'cared', 'career', 'careful', 'caring', 'carrie', 'carried', 'carry', 'carrying', 'cartoon', 'cartoonish', 'case', 'cases', 'cash', 'cast', 'caste', 'casting', 'castlevania', 'casual', 'casually', 'casualties', 'cat', 'catalyst', 'catch', 'catching', 'caught', 'cause', 'caused', 'causes', 'causing', 'cave', 'cbs', 'cease', 'celebration', 'cell', 'cells', 'cemented', 'center', 'centered', 'central', 'centric', 'cents', 'century', 'ceremony', 'certain', 'certainly', 'cg', 'cgi', 'chabon', 'chain', 'chains', 'chair', 'chakotay', 'challenge', 'challenges', 'chamber', 'champion', 'chance', 'chancellor', 'chances', 'change', 'changed', 'changeling', 'changelings', 'changes', 'changing', 'channel', 'channels', 'chaos', 'chapter', 'chapters', 'char', 'character', 'characterization', 'characters', 'charge', 'charm', 'chase', 'chased', 'chasing', 'chatting', 'cheap', 'cheapens', 'cheat', 'cheated', 'check', 'checked', 'checking', 'cheesy', 'chef', 'chekov', 'chemistry', 'cherry', 'chest', 'chewbacca', 'chewie', 'chewing', 'chick', 'chicken', 'chief', 'child', 'childbirth', 'childhood', 'childish', 'children', 'chill', 'chime', 'chip', 'chips', 'choice', 'choices', 'choke', 'choose', 'chooses', 'choosing', 'chopped', 'chore', 'choreography', 'chose', 'chosen', 'christ', 'chronological', 'chronologically', 'cinema', 'cinematic', 'cinematography', 'circa', 'circle', 'circumstance', 'circumstances', 'citadel', 'cities', 'citizens', 'city', 'civil', 'civilian', 'civilians', 'civilization', 'civilizations', 'clad', 'claim', 'claimed', 'claims', 'clancy', 'clash', 'class', 'classes', 'classic', 'classics', 'classified', 'claudia', 'clean', 'clear', 'clearly', 'clever', 'cleverness', 'cliche', 'cliches', 'click', 'cliff', 'cliffhanger', 'climactic', 'climate', 'climax', 'clip', 'clone', 'clones', 'clonewars', 'cloning', 'close', 'closed', 'closely', 'closer', 'closes', 'closest', 'closing', 'clothes', 'cloud', 'clouded', 'clue', 'clues', 'clumsy', 'co', 'cockpit', 'code', 'coffee', 'cogenitor', 'cohesive', 'coincide', 'coincidence', 'coincidences', 'cold', 'coleman', 'collage', 'collection', 'collective', 'college', 'colony', 'color', 'colored', 'colors', 'colour', 'colours', 'com', 'combat', 'combination', 'combine', 'combined', 'come', 'comedic', 'comedy', 'comes', 'comfort', 'comfortable', 'comforting', 'comic', 'comical', 'comics', 'coming', 'command', 'commanded', 'commander', 'commanding', 'commando', 'commandos', 'comment', 'commentary', 'comments', 'commit', 'commitment', 'committed', 'committing', 'commodore', 'commodores', 'common', 'commonly', 'commonwealth', 'communicates', 'communicating', 'communities', 'community', 'company', 'comparable', 'compare', 'compared', 'comparing', 'comparison', 'compass', 'compelling', 'competent', 'compile', 'complained', 'complaining', 'complaint', 'complaints', 'complete', 'completed', 'completely', 'completing', 'complex', 'complexity', 'complicated', 'composition', 'comprehensive', 'computer', 'computers', 'con', 'conceit', 'conceived', 'concept', 'concepts', 'conceptually', 'concern', 'concerned', 'concerning', 'concerns', 'conclude', 'concluded', 'conclusion', 'condemn', 'condition', 'conditions', 'conducted', 'conduit', 'confidante', 'confidence', 'confident', 'confirmed', 'conflict', 'conflicted', 'conflicting', 'conflicts', 'confront', 'confrontation', 'confronting', 'confused', 'confusing', 'connect', 'connected', 'connecting', 'connection', 'connections', 'conquer', 'conscience', 'conscious', 'consciously', 'consciousness', 'consensus', 'consequence', 'consequences', 'consider', 'considerable', 'considerate', 'consideration', 'considered', 'considereding', 'considering', 'consistency', 'consistent', 'consistently', 'conspiracy', 'constant', 'constantly', 'constitution', 'constraints', 'constructed', 'construction', 'contact', 'contacts', 'contain', 'contained', 'contemplative', 'contemporary', 'contend', 'content', 'contents', 'context', 'contextual', 'contingent', 'continuation', 'continue', 'continued', 'continues', 'continuing', 'continuity', 'continuum', 'contract', 'contracted', 'contradicted', 'contradiction', 'contradictions', 'contradicts', 'contrast', 'control', 'controllables', 'controlled', 'controlling', 'controversial', 'convenient', 'convention', 'conversation', 'conversations', 'convert', 'convince', 'convinced', 'convincing', 'convoluted', 'cool', 'coolest', 'copies', 'coppelius', 'copy', 'copying', 'core', 'corellia', 'corner', 'coronavirus', 'corpse', 'correct', 'correlated', 'correlation', 'corridors', 'corruption', 'coruscant', 'cost', 'costs', 'costumes', 'could', 'couldve', 'council', 'count', 'counter', 'counterpart', 'countless', 'country', 'couple', 'courage', 'course', 'cousin', 'cover', 'covered', 'covering', 'covers', 'covid', 'craft', 'crait', 'crap', 'crappy', 'crash', 'crashed', 'crashing', 'crawl', 'crazy', 'cream', 'create', 'created', 'creates', 'creating', 'creation', 'creative', 'creativity', 'creatures', 'credible', 'credit', 'credits', 'crew', 'crewmembers', 'crews', 'cried', 'crime', 'cringe', 'cringey', 'crisis', 'criteria', 'critical', 'criticism', 'criticisms', 'criticize', 'criticized', 'criticizing', 'critique', 'cross', 'crossed', 'crossfire', 'crossing', 'crossover', 'crucial', 'cruel', 'cruiser', 'crusher', 'crying', 'crystal', 'crystals', 'cube', 'culmination', 'cultural', 'culture', 'cultures', 'cunning', 'cupboard', 'curious', 'current', 'currently', 'custom', 'cut', 'cute', 'cuts', 'cutting', 'cuz', 'cw', 'cybernetic', 'cyborg', 'cycle', 'cynical', 'da', 'dad', 'dagger', 'dagobah', 'daily', 'damage', 'damaged', 'damages', 'dameron', 'damn', 'danger', 'dangerous', 'dark', 'darker', 'darkness', 'darksaber', 'dart', 'darth', 'dash', 'data', 'date', 'dated', 'dates', 'daughter', 'dave', 'dawn', 'dax', 'day', 'days', 'daystrominstitute', 'de', 'dead', 'deal', 'dealing', 'deals', 'dear', 'death', 'deaths', 'debate', 'decade', 'decades', 'decent', 'decide', 'decided', 'decides', 'decision', 'decisions', 'deck', 'decks', 'dedicated', 'dedication', 'deduced', 'deemed', 'deep', 'deeper', 'deeply', 'defeat', 'defeated', 'defeats', 'defected', 'defective', 'defence', 'defend', 'defended', 'defending', 'defense', 'defensive', 'defiant', 'define', 'defined', 'definitely', 'definition', 'definitive', 'deflecting', 'degree', 'deliberately', 'delight', 'deliver', 'delivered', 'delivering', 'delivery', 'delta', 'demand', 'demands', 'demilitarised', 'demons', 'demonstrates', 'deng', 'dengar', 'denied', 'deny', 'denying', 'depa', 'depending', 'depends', 'depicted', 'depiction', 'deploy', 'depressed', 'depressing', 'depth', 'deridex', 'derived', 'derives', 'descending', 'descent', 'describe', 'described', 'describes', 'description', 'descriptions', 'desert', 'deserve', 'deserved', 'deserves', 'design', 'designed', 'designs', 'desire', 'desires', 'despair', 'desperate', 'desperately', 'despite', 'destabilise', 'destabilize', 'destiny', 'destroy', 'destroyed', 'destroyer', 'destroyers', 'destroying', 'destroys', 'destruction', 'detail', 'detailed', 'details', 'determination', 'determined', 'detracts', 'deus', 'devastated', 'devastating', 'develop', 'developed', 'developing', 'development', 'device', 'devolved', 'devotion', 'di', 'dialogue', 'dice', 'dictated', 'dictionary', 'didnt', 'die', 'died', 'dies', 'differed', 'difference', 'differences', 'different', 'differently', 'difficult', 'diffrent', 'digital', 'digitally', 'dilemma', 'dilithium', 'dim', 'dimensional', 'din', 'dinner', 'diplomacy', 'diplomatic', 'direct', 'directed', 'directing', 'direction', 'directive', 'directly', 'director', 'directors', 'dirty', 'dis', 'disagree', 'disagrees', 'disappear', 'disappeared', 'disappointed', 'disappointing', 'disappointment', 'disappoints', 'disaster', 'disastrous', 'disc', 'discard', 'disciple', 'discipline', 'disco', 'disconcerted', 'disconnected', 'discord', 'discover', 'discovered', 'discovering', 'discovers', 'discovery', 'discrimination', 'discuss', 'discussed', 'discussing', 'discussion', 'discussions', 'disease', 'diseases', 'disgrace', 'disgusting', 'dishonest', 'disinterested', 'dislike', 'disliked', 'disliking', 'disney', 'disobey', 'dispatch', 'display', 'displayed', 'dispute', 'disrespect', 'disrespectful', 'distance', 'distancing', 'distant', 'distaste', 'distinct', 'distinctively', 'distract', 'distracting', 'distress', 'distrust', 'disturbing', 'dive', 'diverse', 'divide', 'divided', 'division', 'divisions', 'divisive', 'dixon', 'dna', 'doc', 'docking', 'docks', 'doctor', 'doctors', 'dodging', 'dog', 'dogma', 'dogmatically', 'dominion', 'donatu', 'done', 'dont', 'dooku', 'doom', 'door', 'dope', 'dork', 'double', 'doubt', 'doug', 'dour', 'downfall', 'download', 'downs', 'downvote', 'downvoted', 'downvotes', 'downward', 'dr', 'drag', 'dragged', 'dragging', 'drain', 'drallig', 'drama', 'dramatic', 'dramatically', 'drank', 'drastically', 'draw', 'drawing', 'drawn', 'dreading', 'dreadnought', 'dream', 'dreamed', 'dreams', 'dresses', 'dressing', 'drink', 'drinking', 'drive', 'driven', 'driver', 'driving', 'droid', 'droids', 'drone', 'drones', 'drop', 'dropped', 'dropping', 'drove', 'drunk', 'drunken', 'dry', 'ds', 'dude', 'due', 'duel', 'dueling', 'duels', 'dukat', 'dull', 'dumb', 'dump', 'dust', 'duty', 'dvd', 'dvds', 'dwight', 'dyad', 'dyas', 'dying', 'dynamic', 'ea', 'eager', 'ear', 'earl', 'earlier', 'early', 'earn', 'earned', 'ears', 'earth', 'ease', 'easier', 'easily', 'easter', 'easy', 'eat', 'echo', 'eckstein', 'economic', 'economy', 'ect', 'ed', 'edge', 'edgy', 'edit', 'editing', 'edition', 'editions', 'edits', 'edo', 'education', 'edward', 'edwards', 'eekar', 'eeth', 'effect', 'effective', 'effectively', 'effects', 'efficient', 'efficiently', 'effort', 'efforts', 'egg', 'ego', 'egregious', 'eh', 'ehrenreich', 'eight', 'either', 'elaborate', 'elanna', 'element', 'elements', 'elim', 'eliminate', 'eliminated', 'elite', 'elnor', 'else', 'embodiment', 'embraced', 'embracing', 'emissary', 'emotion', 'emotional', 'emotionally', 'emotions', 'empathy', 'emperor', 'empire', 'employ', 'empty', 'encounter', 'encountered', 'encouraging', 'end', 'ended', 'endgame', 'ending', 'endings', 'endor', 'ends', 'enemies', 'enemy', 'energy', 'engage', 'engaged', 'engaging', 'engineering', 'english', 'enisence', 'enjoy', 'enjoyable', 'enjoyed', 'enjoying', 'enough', 'ensemble', 'ensign', 'ensure', 'ent', 'enter', 'entering', 'enterprise', 'entertaining', 'entertainment', 'enthusiastic', 'entire', 'entirely', 'entirety', 'entity', 'entry', 'environment', 'ep', 'epic', 'episode', 'episodes', 'episodic', 'equal', 'equally', 'equivalent', 'er', 'era', 'error', 'ertay', 'esb', 'escape', 'escaped', 'escaping', 'especially', 'essence', 'essential', 'essentially', 'establish', 'established', 'establishing', 'etc', 'eternal', 'ethical', 'ethics', 'eu', 'even', 'evening', 'event', 'events', 'eventually', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everytime', 'everywhere', 'evidence', 'evil', 'evolved', 'ewoks', 'ex', 'exact', 'exactly', 'examining', 'example', 'examples', 'excellent', 'except', 'exception', 'exchange', 'excited', 'exciting', 'exclusive', 'excuse', 'executed', 'exegol', 'exile', 'exist', 'existence', 'existing', 'exists', 'expand', 'expanded', 'expanding', 'expect', 'expectations', 'expected', 'expecting', 'experience', 'experienced', 'experiences', 'experiencing', 'experiment', 'explain', 'explained', 'explaining', 'explains', 'explanation', 'explicitly', 'exploration', 'explore', 'explored', 'explorers', 'exploring', 'explosion', 'express', 'expressed', 'extension', 'extent', 'extra', 'extreme', 'extremely', 'extremist', 'eye', 'eyes', 'ezra', 'face', 'faces', 'facial', 'facility', 'facing', 'fact', 'faction', 'factions', 'factors', 'facts', 'faded', 'failed', 'failing', 'fails', 'failure', 'fair', 'fairly', 'faith', 'faithful', 'fajo', 'fake', 'falcon', 'fall', 'fallen', 'falling', 'fallout', 'falls', 'false', 'familiar', 'families', 'family', 'famous', 'fan', 'fanbase', 'fancy', 'fandom', 'fanfic', 'fanfiction', 'fans', 'fanservice', 'fantastic', 'fantasy', 'far', 'farm', 'fashion', 'fashioned', 'fast', 'faster', 'fate', 'father', 'fathers', 'fault', 'favor', 'favorite', 'favorites', 'favourite', 'favreau', 'fear', 'fears', 'feats', 'featured', 'features', 'featuring', 'federal', 'federation', 'feel', 'feeling', 'feelings', 'feels', 'feet', 'fell', 'fellow', 'felt', 'female', 'fenris', 'ferengi', 'fett', 'fi', 'fiction', 'fictional', 'field', 'fight', 'fighter', 'fighters', 'fighting', 'fights', 'figure', 'figured', 'figures', 'files', 'fill', 'filled', 'filler', 'filling', 'film', 'filmed', 'filming', 'filmmakers', 'films', 'filoni', 'final', 'finale', 'finally', 'financially', 'find', 'finding', 'finds', 'fine', 'finger', 'finish', 'finished', 'finishing', 'finn', 'fire', 'firing', 'first', 'firstly', 'fisher', 'fisto', 'fit', 'fits', 'fitting', 'five', 'fix', 'fixed', 'flag', 'flagship', 'flashback', 'flashbacks', 'flat', 'flaw', 'flawed', 'flaws', 'fleet', 'flesh', 'fleshed', 'flight', 'floor', 'flow', 'flowers', 'fluidity', 'fly', 'flying', 'fo', 'focus', 'focused', 'focuses', 'foe', 'foils', 'folks', 'follow', 'followed', 'following', 'follows', 'food', 'fool', 'fools', 'footage', 'forbidden', 'force', 'forced', 'forces', 'forcing', 'ford', 'foreshadowing', 'forever', 'forge', 'forget', 'forgetting', 'forgive', 'forgot', 'forgotten', 'form', 'formal', 'format', 'former', 'forms', 'forth', 'fortunately', 'forward', 'fought', 'found', 'foundation', 'founders', 'four', 'fourth', 'frakes', 'frame', 'framed', 'franchise', 'frankly', 'freaking', 'free', 'freecloud', 'freedom', 'freeze', 'frequency', 'frequent', 'frequently', 'fresh', 'friday', 'friend', 'friendly', 'friends', 'friendship', 'front', 'frontier', 'frozen', 'frustrated', 'frustrating', 'frustration', 'fuck', 'fucked', 'fucking', 'fuel', 'fulcrum', 'full', 'fully', 'fun', 'function', 'fundamentally', 'funny', 'furthermore', 'future', 'gain', 'gained', 'galactic', 'galaxy', 'galen', 'gallia', 'game', 'games', 'gang', 'gangster', 'gaps', 'garak', 'garbage', 'gatherings', 'gave', 'gay', 'gear', 'gel', 'gen', 'gender', 'gene', 'general', 'generally', 'generation', 'generations', 'generic', 'genetic', 'genetically', 'genocide', 'genre', 'gentle', 'genuine', 'genuinely', 'geordi', 'george', 'georgiou', 'ger', 'gesture', 'get', 'gets', 'getting', 'ghost', 'giant', 'gideon', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'giving', 'glad', 'glance', 'glory', 'go', 'goal', 'god', 'gods', 'goes', 'going', 'gold', 'golden', 'gon', 'gone', 'gonna', 'good', 'goodbye', 'goodness', 'google', 'gorgeous', 'gorn', 'got', 'gotta', 'gotten', 'government', 'grab', 'grace', 'grade', 'grand', 'granddaughter', 'grandfather', 'granted', 'graphic', 'graphics', 'grateful', 'gravity', 'gray', 'great', 'greater', 'greatest', 'greatly', 'greed', 'green', 'grevious', 'grew', 'grey', 'grief', 'grievous', 'ground', 'group', 'groups', 'grow', 'growing', 'grown', 'grows', 'growth', 'gsynerria', 'guarantee', 'guard', 'guards', 'guess', 'guessing', 'guest', 'guidance', 'guide', 'guilt', 'guilty', 'guinan', 'gul', 'gun', 'gut', 'guy', 'guys', 'ha', 'hadar', 'haha', 'hair', 'half', 'halfway', 'halsey', 'hamill', 'han', 'hand', 'handedly', 'handle', 'handled', 'hands', 'hang', 'hanging', 'happen', 'happened', 'happening', 'happens', 'happier', 'happy', 'hard', 'hardcore', 'hardly', 'harm', 'harmony', 'harrison', 'harry', 'harsh', 'hat', 'hate', 'hated', 'hates', 'hating', 'hatred', 'havent', 'head', 'headcanon', 'headed', 'heading', 'heads', 'heal', 'healer', 'healing', 'health', 'healthy', 'hear', 'heard', 'hearing', 'heart', 'hearted', 'heated', 'heaven', 'heavily', 'heavy', 'heck', 'held', 'hell', 'hello', 'helm', 'helmet', 'help', 'helped', 'helping', 'helps', 'hence', 'hera', 'hero', 'heroes', 'heroic', 'hesa', 'hey', 'hi', 'hidden', 'hide', 'hiding', 'high', 'highlight', 'highly', 'hilarious', 'hill', 'hilt', 'hint', 'hinted', 'hints', 'hisen', 'history', 'hit', 'hitting', 'hive', 'hold', 'holding', 'holdo', 'holds', 'hole', 'holes', 'holiday', 'hollow', 'hollywood', 'holo', 'holocron', 'holodeck', 'hologram', 'holograms', 'holographic', 'holosuite', 'holy', 'home', 'homeworld', 'honest', 'honestly', 'honor', 'honorable', 'hook', 'hooked', 'hope', 'hoped', 'hopeful', 'hopefully', 'hopes', 'hoping', 'horrendous', 'horrible', 'horrific', 'host', 'hostile', 'hot', 'hoth', 'hour', 'hours', 'house', 'however', 'huge', 'hugh', 'hull', 'human', 'humanist', 'humanity', 'humans', 'humble', 'hundred', 'hundreds', 'hunt', 'hunted', 'hunter', 'hunters', 'hunting', 'hunts', 'hurt', 'husband', 'hux', 'hyped', 'hyperspace', 'ian', 'ice', 'icheb', 'iconic', 'id', 'idea', 'ideal', 'ideals', 'ideas', 'identity', 'ideology', 'idk', 'ignorance', 'ignore', 'ignored', 'ignores', 'ignoring', 'ii', 'iii', 'ill', 'illegal', 'illum', 'illusion', 'im', 'ima', 'image', 'imagination', 'imagine', 'imagined', 'immediately', 'immortal', 'imo', 'impact', 'impactful', 'imperfect', 'imperfection', 'imperfections', 'imperial', 'imperials', 'implications', 'importance', 'important', 'importantly', 'impossible', 'impression', 'impressive', 'improve', 'improved', 'impulsive', 'incident', 'include', 'included', 'includes', 'including', 'increase', 'increased', 'incredible', 'incredibly', 'indeed', 'indication', 'individual', 'individuality', 'individuals', 'induced', 'inferior', 'infinite', 'influence', 'influenced', 'info', 'information', 'ingenuity', 'inhabitants', 'initial', 'initially', 'inner', 'innocent', 'input', 'inquisitor', 'inquisitors', 'ins', 'insane', 'insert', 'inside', 'insight', 'insights', 'inspiration', 'inspired', 'inspiring', 'instance', 'instances', 'instant', 'instantly', 'instead', 'instinct', 'insulting', 'insurrection', 'integral', 'intelligence', 'intended', 'intense', 'intentional', 'intentions', 'interact', 'interaction', 'interactions', 'interest', 'interested', 'interesting', 'internet', 'interpret', 'interpretation', 'intimidating', 'intrigued', 'intriguing', 'introduce', 'introduced', 'introduces', 'introducing', 'introduction', 'invasion', 'invested', 'involve', 'involved', 'involving', 'ion', 'irl', 'iron', 'irrelevant', 'ish', 'island', 'isnt', 'isolated', 'isolation', 'issue', 'issues', 'items', 'iteration', 'iv', 'ive', 'ix', 'jack', 'jadzia', 'jake', 'jakku', 'james', 'janeway', 'jar', 'jarring', 'jarrus', 'jean', 'jedi', 'jem', 'jewish', 'ji', 'jill', 'jinn', 'jj', 'jlp', 'job', 'jobs', 'jocasta', 'john', 'johnson', 'join', 'joined', 'joining', 'jojo', 'joke', 'jokes', 'jones', 'journey', 'joy', 'judge', 'judgement', 'judgments', 'jukassa', 'julian', 'juliana', 'jump', 'jumped', 'jumping', 'jumps', 'junk', 'juno', 'jur', 'jurati', 'justice', 'justified', 'justifying', 'kai', 'kanan', 'kara', 'kashyyk', 'katan', 'katarn', 'kathleen', 'kazon', 'kcaj', 'keep', 'keeping', 'keeps', 'keiko', 'kelvin', 'kennedy', 'kenobi', 'kept', 'kes', 'kessel', 'kestis', 'kestra', 'kevin', 'key', 'keychain', 'keys', 'khan', 'ki', 'kick', 'kicks', 'kid', 'kidnapped', 'kidnaps', 'kids', 'kijimi', 'kill', 'killed', 'killer', 'killing', 'kills', 'kim', 'kind', 'kinda', 'kinds', 'king', 'kingdom', 'kira', 'kirk', 'kiss', 'kistra', 'kit', 'klingon', 'klingons', 'knew', 'knight', 'knights', 'knocking', 'know', 'knowing', 'knowledge', 'known', 'knows', 'knox', 'kolar', 'koon', 'kor', 'kota', 'koth', 'kotor', 'kree', 'krell', 'kurn', 'kurtzman', 'kuvma', 'ky', 'kyber', 'kyle', 'kylo', 'kylos', 'la', 'labor', 'lack', 'lacked', 'lacking', 'lacks', 'lad', 'lady', 'laid', 'lal', 'lame', 'land', 'landed', 'lander', 'landing', 'lando', 'lands', 'language', 'languages', 'large', 'largely', 'larger', 'laser', 'lasers', 'last', 'lasted', 'lasting', 'lastly', 'lasts', 'late', 'lately', 'later', 'latest', 'latino', 'latter', 'laugh', 'laughing', 'laughs', 'launch', 'launched', 'laundry', 'lava', 'law', 'lay', 'laying', 'lazy', 'lead', 'leader', 'leaders', 'leadership', 'leading', 'leads', 'leap', 'learn', 'learned', 'learning', 'learns', 'least', 'leave', 'leaves', 'leaving', 'led', 'lee', 'left', 'leg', 'legacy', 'legend', 'legendary', 'legends', 'legitimate', 'legitimately', 'lego', 'legs', 'leia', 'lek', 'leland', 'length', 'lengths', 'lens', 'leonard', 'less', 'lesser', 'lesson', 'lessons', 'let', 'lets', 'letter', 'letting', 'level', 'levelled', 'levels', 'liar', 'liberated', 'library', 'licensed', 'lie', 'lies', 'lieutenant', 'life', 'lifeforms', 'lifeless', 'lifelike', 'lifeline', 'lifespan', 'lifetime', 'lifted', 'light', 'lighter', 'lighting', 'lightning', 'lightsaber', 'lightsabers', 'like', 'liked', 'likely', 'likes', 'liking', 'liko', 'limbs', 'limitations', 'limited', 'limitless', 'line', 'lineage', 'linear', 'lines', 'lingering', 'lingo', 'link', 'linking', 'links', 'lips', 'list', 'listed', 'listen', 'listening', 'listens', 'literal', 'literally', 'little', 'live', 'lived', 'lives', 'living', 'lmao', 'load', 'loans', 'local', 'location', 'locations', 'lock', 'lockdown', 'locked', 'locking', 'locks', 'locutus', 'logic', 'logical', 'lol', 'long', 'longed', 'longer', 'longstanding', 'longtime', 'look', 'looked', 'looking', 'looks', 'loophole', 'loose', 'loosing', 'lorca', 'lord', 'lords', 'lore', 'lose', 'loses', 'losing', 'loss', 'losses', 'lost', 'lot', 'lothal', 'lotr', 'lots', 'loud', 'love', 'loved', 'lovely', 'lover', 'lovers', 'loves', 'loving', 'low', 'lower', 'loyal', 'loyalty', 'luc', 'lucas', 'lucasfilm', 'luck', 'luckily', 'lucky', 'luke', 'luminara', 'lure', 'lush', 'luxury', 'lwaxana', 'lying', 'mace', 'machete', 'machina', 'machine', 'machines', 'macroviruses', 'mad', 'maddox', 'made', 'magazine', 'magazines', 'magic', 'magical', 'magneto', 'main', 'mainly', 'maintain', 'major', 'majority', 'make', 'makes', 'makeup', 'making', 'male', 'malevolent', 'malfunction', 'malfunctioning', 'mammals', 'man', 'manage', 'managed', 'manager', 'manages', 'mandalore', 'mandalorian', 'mandalorians', 'mando', 'mandolorian', 'manifest', 'manipulate', 'manipulated', 'manner', 'mans', 'manufactured', 'many', 'map', 'maquis', 'mara', 'marathon', 'marathoned', 'marekk', 'margin', 'mark', 'market', 'marking', 'marks', 'marquis', 'marriages', 'married', 'mars', 'martial', 'martin', 'marvel', 'mary', 'mask', 'masks', 'mass', 'massive', 'massively', 'master', 'mastered', 'mastermind', 'masters', 'mastery', 'match', 'material', 'materials', 'matrix', 'matt', 'matter', 'matters', 'mature', 'maul', 'max', 'may', 'maybe', 'mccoy', 'mcdiarmid', 'mcu', 'mean', 'meaning', 'meaningful', 'meaningless', 'means', 'meant', 'meanwhile', 'measure', 'mechanic', 'mechanical', 'mechanics', 'media', 'medical', 'medicine', 'medieval', 'mediocre', 'meditating', 'meditation', 'meditative', 'medium', 'mediums', 'meet', 'meeting', 'meets', 'mega', 'megalomania', 'meh', 'meld', 'melodrama', 'melted', 'member', 'members', 'meme', 'memes', 'memorable', 'memories', 'memory', 'men', 'menace', 'mental', 'mentally', 'mention', 'mentioned', 'mentioning', 'mentions', 'mentor', 'mercy', 'merely', 'mess', 'message', 'messed', 'messenger', 'met', 'meta', 'metal', 'metallic', 'methodology', 'mexico', 'michael', 'mickey', 'micro', 'mid', 'middle', 'midichlorians', 'midway', 'might', 'mighty', 'mild', 'miles', 'military', 'millennium', 'million', 'millions', 'mimic', 'min', 'mind', 'minded', 'minds', 'mindset', 'mine', 'mines', 'mini', 'minimal', 'minimum', 'miniseries', 'minor', 'minority', 'minus', 'minute', 'minutes', 'mirror', 'mirrors', 'misleading', 'misread', 'miss', 'missed', 'misses', 'missing', 'mission', 'missions', 'mistake', 'mistakes', 'mitigation', 'mix', 'mixed', 'mixing', 'mmo', 'mobile', 'mode', 'model', 'models', 'modern', 'moff', 'mogh', 'mom', 'moment', 'moments', 'mon', 'monday', 'monetary', 'money', 'monster', 'montage', 'month', 'montha', 'months', 'monumental', 'mood', 'moon', 'moonlight', 'moral', 'morality', 'morally', 'morals', 'morning', 'mortis', 'mospar', 'mostly', 'mother', 'motherfuckin', 'motif', 'motion', 'motions', 'motivate', 'motivated', 'motivation', 'motives', 'mourns', 'mouse', 'mouth', 'move', 'moved', 'movement', 'movements', 'moves', 'movie', 'movies', 'moving', 'mowing', 'mr', 'mual', 'much', 'multi', 'multiple', 'mundi', 'murder', 'murdered', 'murdering', 'murders', 'muscles', 'museum', 'music', 'must', 'mustafar', 'muted', 'mutiny', 'mysterious', 'mystery', 'myth', 'mythic', 'mythology', 'myths', 'naboo', 'nagilum', 'nah', 'nahdar', 'naive', 'name', 'named', 'namely', 'names', 'naming', 'nar', 'narec', 'narek', 'narissa', 'narrative', 'naruto', 'nation', 'national', 'natural', 'naturally', 'nature', 'navigate', 'navy', 'nbsp', 'nd', 'nde', 'near', 'nearly', 'necessarily', 'necessary', 'need', 'needed', 'needs', 'neelix', 'negated', 'negative', 'negativity', 'neither', 'nema', 'nemesis', 'nemisis', 'nepenthe', 'nephew', 'nerd', 'nerds', 'nerdy', 'nervous', 'nerys', 'netflix', 'network', 'neurons', 'neutral', 'never', 'nevermind', 'new', 'newer', 'newest', 'newly', 'news', 'next', 'ng', 'nice', 'night', 'nights', 'nimoy', 'nine', 'nineties', 'ninja', 'nitpick', 'njo', 'noble', 'nobodies', 'nobody', 'nod', 'nog', 'non', 'none', 'nonsense', 'noobs', 'nope', 'normal', 'normally', 'nose', 'nostalgia', 'notably', 'note', 'nothing', 'notice', 'noticed', 'notices', 'notion', 'notsa', 'novel', 'novelization', 'novels', 'nowadays', 'nowhere', 'nth', 'nu', 'nuance', 'nuances', 'number', 'numerous', 'nurse', 'nutrek', 'nuts', 'obi', 'obiwhykonobe', 'object', 'objects', 'obsessed', 'obvious', 'obviously', 'occasionally', 'occupation', 'occupied', 'occurred', 'ocd', 'october', 'odd', 'odds', 'odo', 'offee', 'offer', 'offers', 'officer', 'officers', 'official', 'officially', 'offs', 'offscreen', 'offspring', 'often', 'og', 'oh', 'ok', 'okay', 'oki', 'okmyx', 'old', 'older', 'oldest', 'one', 'ones', 'online', 'onscreen', 'onto', 'onwards', 'open', 'opened', 'opening', 'opens', 'operate', 'operating', 'opinion', 'opinions', 'oppo', 'opponent', 'opportunity', 'opposed', 'opposing', 'opposite', 'optimism', 'optimistic', 'option', 'optional', 'options', 'ord', 'order', 'orders', 'organa', 'organic', 'organics', 'organization', 'origin', 'original', 'originally', 'originals', 'orphaned', 'orville', 'ot', 'others', 'otherwise', 'outcome', 'outer', 'outpost', 'outright', 'outside', 'outstanding', 'overall', 'overarching', 'overcome', 'overlook', 'overlooked', 'overlooking', 'overly', 'overrun', 'overshadowed', 'overthinking', 'overthrow', 'overwhelmed', 'overwhelming', 'owe', 'owen', 'owned', 'owner', 'owns', 'pablo', 'pace', 'paced', 'pacing', 'packed', 'pact', 'padawan', 'padawans', 'padm', 'padme', 'page', 'pages', 'pah', 'paid', 'pain', 'painful', 'paint', 'painted', 'pair', 'palapatine', 'pale', 'palmer', 'palpatin', 'palpatine', 'palpatines', 'palps', 'palpy', 'pandemic', 'panic', 'panning', 'pantora', 'par', 'paradise', 'parallel', 'parallels', 'parameters', 'paramount', 'parent', 'parents', 'paris', 'parody', 'part', 'parter', 'particular', 'particularly', 'partly', 'parts', 'party', 'pass', 'passage', 'passed', 'passion', 'passive', 'past', 'pasted', 'path', 'pathway', 'patience', 'patrick', 'pattern', 'patterns', 'pawn', 'pay', 'payoff', 'pays', 'peace', 'peaceful', 'peak', 'peaks', 'peeve', 'pegasus', 'people', 'per', 'perceive', 'perceived', 'perfect', 'perfectly', 'performance', 'perhaps', 'peril', 'period', 'permanently', 'person', 'personal', 'personalities', 'personality', 'personally', 'perspective', 'pet', 'phantom', 'phase', 'phaser', 'phasers', 'phasma', 'phenomenal', 'phenomenon', 'philosophy', 'phone', 'physical', 'pic', 'picard', 'picards', 'pick', 'picked', 'picture', 'pictured', 'pictures', 'piece', 'pieces', 'pike', 'pilot', 'piloting', 'pipe', 'piss', 'pissed', 'pissing', 'pit', 'pizza', 'place', 'placed', 'places', 'plagueis', 'plaguies', 'plain', 'plan', 'planet', 'planets', 'planned', 'planning', 'plans', 'plant', 'plastic', 'plausible', 'play', 'played', 'player', 'playing', 'plays', 'pleasant', 'please', 'plenty', 'plo', 'plot', 'plots', 'plug', 'plus', 'po', 'pocket', 'pod', 'podcast', 'podracer', 'poe', 'poetic', 'point', 'pointless', 'points', 'pol', 'political', 'politics', 'pondering', 'pong', 'poof', 'pool', 'poor', 'poorly', 'pop', 'popular', 'population', 'portal', 'portray', 'portrayal', 'portrayed', 'portraying', 'pose', 'position', 'positive', 'positronic', 'possibilities', 'possibility', 'possible', 'possibly', 'post', 'posted', 'posting', 'posts', 'potential', 'potentially', 'power', 'powerful', 'powers', 'practices', 'praise', 'prank', 'pre', 'precision', 'predictable', 'prefer', 'preference', 'preferred', 'pregnant', 'prejudice', 'premiere', 'premiered', 'premise', 'prequel', 'prequels', 'presence', 'present', 'presented', 'presents', 'presumably', 'pretend', 'pretty', 'prevent', 'prevented', 'preventing', 'preview', 'previous', 'previously', 'priest', 'priests', 'primarily', 'primary', 'primative', 'prime', 'primitive', 'principles', 'print', 'printed', 'prior', 'prism', 'prison', 'prisoner', 'prisoners', 'pro', 'probability', 'probably', 'problem', 'problems', 'proceed', 'process', 'processing', 'prodigal', 'produced', 'producers', 'product', 'production', 'profanity', 'professional', 'professor', 'profit', 'profound', 'program', 'programs', 'progress', 'progresses', 'progression', 'progressive', 'project', 'projection', 'projects', 'prolly', 'prominent', 'promise', 'promising', 'promoted', 'prompted', 'pronounce', 'proof', 'propaganda', 'proper', 'properly', 'properties', 'prophecies', 'prophecy', 'prophet', 'prophets', 'propose', 'props', 'propulsion', 'pros', 'prospect', 'prosper', 'protag', 'protagonist', 'protagonists', 'protect', 'protecting', 'protection', 'protocol', 'proud', 'prove', 'proved', 'proven', 'proverbial', 'provide', 'provided', 'provides', 'providing', 'provoking', 'proxy', 'ps', 'pseudo', 'psychopath', 'pt', 'ptsd', 'public', 'puked', 'pulaski', 'pull', 'pulled', 'pulling', 'pulls', 'pumping', 'pun', 'punch', 'punishment', 'purchase', 'pure', 'purely', 'purge', 'purify', 'purple', 'purpose', 'purposes', 'pursuit', 'pursuits', 'push', 'pushed', 'pushes', 'pushing', 'put', 'puts', 'putting', 'puzzle', 'pykes', 'qi', 'quadrant', 'quality', 'quarantine', 'quark', 'quarters', 'quasar', 'queen', 'quest', 'question', 'questionable', 'questioned', 'questions', 'qui', 'quick', 'quickly', 'quiet', 'quinlan', 'quirky', 'quit', 'quite', 'quote', 'quotes', 'ra', 'race', 'races', 'racing', 'racist', 'rafa', 'raffi', 'rag', 'rage', 'raged', 'rahm', 'raising', 'rambling', 'rampage', 'rams', 'ran', 'rancisis', 'random', 'randomly', 'range', 'rangers', 'ranging', 'rank', 'ranked', 'ranking', 'rankings', 'ranks', 'rant', 'ranting', 'rare', 'rarely', 'rate', 'rated', 'rather', 'rating', 'ration', 'rationale', 'raven', 'raw', 'raxus', 'ray', 'rd', 'reach', 'reached', 'reaches', 'reaching', 'react', 'reacting', 'reaction', 'reactions', 'reactivated', 'reacts', 'read', 'reading', 'reads', 'ready', 'real', 'realise', 'realised', 'realism', 'realistic', 'reality', 'realization', 'realize', 'realized', 'realizes', 'realizing', 'really', 'realm', 'reaper', 'reapers', 'rear', 'reason', 'reasonable', 'reasoning', 'reasons', 'rebel', 'rebellion', 'rebels', 'reboot', 'reborn', 'rebuild', 'rebuilt', 'rec', 'recall', 'receive', 'received', 'receives', 'recent', 'recently', 'reckon', 'reclamation', 'recognise', 'recognised', 'recognize', 'recognized', 'recognizes', 'recommend', 'recommendations', 'recommending', 'reconcile', 'recorded', 'recover', 'recreate', 'recruit', 'rectangular', 'recurring', 'recyclers', 'red', 'reddick', 'reddit', 'redditors', 'redeem', 'redeemed', 'redemption', 'redesign', 'reduced', 'reed', 'refer', 'reference', 'references', 'referencing', 'referred', 'referring', 'refers', 'refinement', 'reflect', 'reflection', 'reflects', 'refugees', 'refuse', 'refused', 'refuses', 'regain', 'regard', 'regarded', 'regarding', 'regardless', 'regards', 'regions', 'registration', 'regress', 'regret', 'regrown', 'regular', 'regularly', 'regulate', 'regulation', 'regulations', 'rehashed', 'reigns', 'reinforcements', 'reject', 'rejected', 'relatable', 'relate', 'related', 'relatedly', 'relates', 'relations', 'relationship', 'relationships', 'relative', 'relatively', 'relay', 'release', 'released', 'releases', 'relevant', 'relics', 'relief', 'relieved', 'religion', 'religious', 'reluctantly', 'remain', 'remaining', 'remake', 'remakes', 'remember', 'remembered', 'remembering', 'remind', 'reminded', 'reminds', 'reminiscent', 'remnant', 'remnants', 'remotely', 'remove', 'removed', 'removing', 'remus', 'ren', 'renders', 'rent', 'rep', 'repair', 'repaired', 'repeat', 'repeated', 'repeatedly', 'repeating', 'replace', 'replaced', 'replacement', 'replicate', 'replicated', 'replicator', 'replicators', 'report', 'reportedly', 'reports', 'represent', 'representation', 'represented', 'represents', 'republic', 'reputation', 'request', 'require', 'required', 'requirements', 'requires', 'reruns', 'rescue', 'rescued', 'research', 'researches', 'resentment', 'reserve', 'resist', 'resistance', 'resisted', 'resists', 'resolve', 'resolved', 'resolving', 'resonance', 'resonate', 'resonated', 'resort', 'resource', 'resources', 'respect', 'respond', 'responds', 'response', 'responsibility', 'responsible', 'rest', 'restart', 'restaurant', 'restaurants', 'restore', 'restored', 'restores', 'restraint', 'result', 'resulting', 'results', 'resume', 'resurrected', 'retcon', 'retconned', 'retconning', 'retcons', 'retelling', 'retired', 'retroactively', 'return', 'returned', 'returning', 'returns', 'reunion', 'reunite', 'reuniting', 'revan', 'reveal', 'revealed', 'revealing', 'reveals', 'revelation', 'revenge', 'reverse', 'reviews', 'revolutionary', 'revolved', 'rewatch', 'rewatched', 'rewatching', 'rewritten', 'rex', 'rey', 'rian', 'ribbon', 'rich', 'richard', 'rid', 'ride', 'ridiculous', 'riding', 'rifle', 'rig', 'right', 'rightful', 'rights', 'riker', 'rikers', 'rim', 'rings', 'rios', 'rip', 'ripe', 'rise', 'rises', 'rising', 'risk', 'risks', 'ritual', 'rival', 'ro', 'road', 'roars', 'robes', 'robotic', 'robots', 'rock', 'rocket', 'rocks', 'roddenberry', 'rogue', 'role', 'roles', 'roll', 'rolled', 'rolling', 'rom', 'roman', 'romance', 'romantic', 'romp', 'romulan', 'romulans', 'romulus', 'roof', 'room', 'rooted', 'rooting', 'ropal', 'ros', 'rosario', 'rose', 'rothgar', 'rotj', 'rots', 'rouge', 'rough', 'roughly', 'round', 'route', 'row', 'royal', 'rpg', 'rude', 'rug', 'ruin', 'ruined', 'ruining', 'rule', 'ruled', 'rules', 'rumored', 'rumors', 'run', 'runner', 'running', 'runs', 'ruse', 'rush', 'rushed', 'rushes', 'ryan', 'saber', 'sabers', 'sabine', 'sacrifice', 'sacrificed', 'sacrifices', 'sacrificing', 'sad', 'sadly', 'sadness', 'saesee', 'safe', 'safeties', 'safety', 'saga', 'said', 'saints', 'sake', 'salt', 'sam', 'sample', 'samuel', 'samurai', 'san', 'sand', 'sanitizer', 'sans', 'sarcastic', 'sarek', 'sarlacc', 'saru', 'satine', 'satire', 'satisfying', 'saturday', 'sauce', 'saucer', 'savage', 'save', 'saved', 'saves', 'saving', 'saw', 'say', 'saying', 'says', 'scale', 'scan', 'scar', 'scarcity', 'scared', 'scary', 'scavenger', 'scenario', 'scenarios', 'scene', 'scenes', 'schizoid', 'school', 'schultz', 'sci', 'science', 'scientific', 'scientists', 'scifi', 'scope', 'score', 'scores', 'scorpion', 'scotty', 'scrapped', 'scratch', 'scream', 'screamed', 'screen', 'screw', 'screwed', 'script', 'scripts', 'sealed', 'search', 'searched', 'searches', 'searching', 'season', 'seasons', 'seat', 'seats', 'sebulba', 'sec', 'second', 'secondly', 'seconds', 'secret', 'secretly', 'section', 'sector', 'secura', 'secure', 'security', 'see', 'seeing', 'seek', 'seem', 'seemed', 'seemingly', 'seems', 'seen', 'sees', 'sela', 'self', 'selling', 'senate', 'senator', 'senators', 'send', 'sending', 'sends', 'senior', 'sense', 'senses', 'sensitive', 'sensitivity', 'sent', 'sentence', 'sentient', 'sentiment', 'separate', 'separatist', 'separatists', 'sequel', 'sequels', 'sequence', 'sequences', 'serenity', 'series', 'serious', 'seriously', 'serve', 'served', 'server', 'serves', 'service', 'serving', 'set', 'sets', 'setting', 'setup', 'seven', 'several', 'sex', 'sexual', 'sexuality', 'sexy', 'sh', 'shaak', 'shadow', 'shadows', 'shady', 'shall', 'shallow', 'shame', 'shape', 'shapes', 'shapeshifters', 'share', 'shared', 'sheer', 'sheev', 'shiar', 'shield', 'shields', 'shift', 'shiny', 'shinzon', 'ship', 'ships', 'shirt', 'shit', 'shock', 'shocked', 'shoot', 'short', 'shorter', 'shortly', 'shot', 'shots', 'shoulders', 'show', 'showdown', 'showed', 'showing', 'shown', 'shows', 'shut', 'sibling', 'sick', 'side', 'sides', 'sidious', 'siege', 'sifo', 'sign', 'signal', 'significant', 'significantly', 'signing', 'silence', 'silent', 'silliness', 'silly', 'sim', 'similar', 'similarities', 'similarity', 'similarly', 'similiar', 'simple', 'simplified', 'simply', 'simpsons', 'simulation', 'since', 'sincerity', 'sing', 'single', 'sinube', 'sir', 'sirena', 'sisko', 'sister', 'sisters', 'sit', 'site', 'sith', 'sitting', 'situation', 'situations', 'six', 'size', 'sized', 'sizes', 'sjw', 'skill', 'skills', 'skin', 'skinned', 'skip', 'skipped', 'skipping', 'sky', 'skywalker', 'skywalkers', 'slaughtered', 'slave', 'slavery', 'slaves', 'sleep', 'slightly', 'slim', 'slipping', 'sloppy', 'slow', 'slowly', 'small', 'smaller', 'smart', 'smarter', 'smarty', 'smell', 'smile', 'smoke', 'snoke', 'social', 'societies', 'society', 'soil', 'soji', 'sold', 'soldiers', 'solid', 'solids', 'solo', 'solution', 'solved', 'solving', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'son', 'song', 'soo', 'soon', 'soong', 'sorry', 'sort', 'sorta', 'sorts', 'soul', 'sound', 'sounded', 'sounds', 'source', 'soviet', 'soviets', 'space', 'spaceship', 'spare', 'speak', 'speaking', 'speaks', 'special', 'species', 'specific', 'specifically', 'spectacle', 'specter', 'speech', 'speed', 'speeder', 'spend', 'spending', 'spends', 'spent', 'sphere', 'spice', 'spies', 'spin', 'spiner', 'spirit', 'spirits', 'spiritual', 'spite', 'split', 'splitting', 'spock', 'spoil', 'spoiled', 'spoiler', 'spoilers', 'spoiling', 'spoke', 'spoof', 'spore', 'spot', 'spots', 'spouting', 'spread', 'spy', 'squad', 'squadron', 'squared', 'st', 'stab', 'stabbed', 'stability', 'stabs', 'staff', 'stage', 'stake', 'stakes', 'stale', 'stamina', 'stance', 'stand', 'standalone', 'standard', 'standards', 'standing', 'standoff', 'standpoint', 'stands', 'star', 'stardate', 'starfleet', 'staring', 'starkiller', 'stars', 'starship', 'starships', 'start', 'started', 'starters', 'starting', 'startrek', 'starts', 'starwars', 'starwarsreverse', 'stass', 'state', 'stated', 'statement', 'states', 'stating', 'station', 'stations', 'status', 'stay', 'stayed', 'stays', 'steal', 'stealing', 'stellar', 'stems', 'step', 'stepgrandniece', 'stepgreat', 'steps', 'stereotype', 'stereotypes', 'stern', 'stewart', 'stick', 'sticking', 'still', 'sto', 'stock', 'stoked', 'stomach', 'stone', 'stood', 'stop', 'stopped', 'stopping', 'stops', 'store', 'stories', 'storm', 'stormtrooper', 'stormtroopers', 'story', 'storyline', 'storylines', 'storytelling', 'stove', 'straight', 'stranded', 'strands', 'strange', 'stranger', 'strategic', 'strategy', 'streaming', 'streets', 'strength', 'stretch', 'stretched', 'strictly', 'strike', 'strikes', 'strip', 'strips', 'strive', 'strong', 'stronger', 'struck', 'structure', 'struggle', 'struggled', 'struggles', 'struggling', 'stubborn', 'stuck', 'student', 'students', 'studied', 'studies', 'studio', 'study', 'stuff', 'stuffed', 'stumped', 'stunned', 'stunning', 'stupid', 'style', 'styles', 'sub', 'subject', 'subplot', 'subreddit', 'substance', 'substantive', 'subtle', 'subtlety', 'succeed', 'succeeded', 'success', 'successes', 'successful', 'successfully', 'successor', 'suck', 'sucked', 'sucks', 'sudden', 'suddenly', 'sue', 'suffer', 'suffered', 'suffering', 'suggest', 'suggested', 'suggestion', 'suggestions', 'suggests', 'suicide', 'suit', 'suite', 'suits', 'sulu', 'sum', 'summarized', 'summon', 'summoning', 'sun', 'sunday', 'suns', 'super', 'superb', 'superior', 'superiority', 'supernatural', 'supernova', 'supplies', 'supply', 'support', 'supporting', 'suppose', 'supposed', 'supposedly', 'suppressing', 'supreme', 'suprised', 'sure', 'surely', 'surface', 'surprise', 'surprised', 'surprises', 'surprising', 'surprisingly', 'surrender', 'surrounded', 'surrounding', 'survival', 'survive', 'survived', 'survives', 'surviving', 'survivors', 'suspect', 'suspected', 'suspension', 'sutra', 'sw', 'swap', 'sway', 'swear', 'sweet', 'swerve', 'swift', 'swing', 'swinging', 'switch', 'switching', 'sword', 'swords', 'syfy', 'symbiont', 'symbol', 'symbolic', 'symbolism', 'sympathise', 'sympathizing', 'symptoms', 'syndicate', 'syndicates', 'syndrome', 'synth', 'synthetic', 'synthetics', 'synths', 'system', 'systems', 'ta', 'tab', 'table', 'tactical', 'tactics', 'tad', 'tag', 'tailor', 'take', 'taken', 'takes', 'taking', 'tal', 'tale', 'talent', 'talented', 'talents', 'tales', 'talk', 'talked', 'talking', 'talks', 'tall', 'tamal', 'tano', 'tapestry', 'tardis', 'target', 'tarre', 'tartakovsky', 'tas', 'task', 'taskforce', 'taste', 'tatooine', 'tattoine', 'tattoos', 'taught', 'tcw', 'tea', 'teach', 'teacher', 'teaches', 'teaching', 'teachings', 'team', 'teams', 'tear', 'teared', 'tearing', 'tears', 'tech', 'technical', 'technically', 'technological', 'technologies', 'technology', 'ted', 'tee', 'teen', 'teenage', 'teenager', 'television', 'tell', 'telling', 'tells', 'temper', 'templates', 'temple', 'temporal', 'temporarily', 'temporary', 'temptation', 'ten', 'tend', 'tense', 'tension', 'tensions', 'tera', 'term', 'terms', 'terrible', 'terribly', 'terrifying', 'terror', 'terrorism', 'terrorist', 'terrorists', 'test', 'text', 'texts', 'tfa', 'tfu', 'th', 'thad', 'thank', 'thankful', 'thankfully', 'thanks', 'thats', 'theater', 'theaters', 'theatrical', 'thematic', 'theme', 'themes', 'theoretically', 'theories', 'theory', 'therefore', 'theres', 'thick', 'thier', 'thin', 'thine', 'thing', 'things', 'think', 'thinking', 'thinks', 'third', 'thirty', 'tho', 'thongla', 'thoroughly', 'though', 'thought', 'thoughts', 'thousand', 'thousands', 'thrawn', 'thread', 'threadlike', 'threat', 'threatened', 'threatening', 'threatens', 'threats', 'three', 'threw', 'throne', 'thrones', 'throughout', 'throw', 'throwing', 'thrown', 'throws', 'thru', 'thursday', 'thus', 'ti', 'tide', 'tie', 'tied', 'tier', 'ties', 'tight', 'tiin', 'till', 'tilly', 'time', 'timeframe', 'timeless', 'timeline', 'timelines', 'times', 'timing', 'timothy', 'tint', 'tiny', 'tiplar', 'tiplee', 'tired', 'titanic', 'title', 'titled', 'titles', 'tl', 'tldr', 'tlj', 'tmp', 'tng', 'toast', 'today', 'toe', 'together', 'token', 'told', 'tolerance', 'tolerate', 'tom', 'tomorrow', 'ton', 'tone', 'tones', 'tonight', 'took', 'tool', 'top', 'topic', 'topics', 'torn', 'torpedo', 'torpedoes', 'torres', 'torture', 'tortured', 'tos', 'total', 'totally', 'touch', 'touched', 'touches', 'touching', 'tough', 'toward', 'towards', 'toxic', 'toys', 'tpm', 'trace', 'track', 'tracking', 'trade', 'tradition', 'tragedy', 'tragic', 'trailer', 'trailers', 'train', 'trained', 'training', 'traits', 'transfer', 'transferred', 'transformation', 'transformed', 'transport', 'transporter', 'transporters', 'transwarp', 'trap', 'trapped', 'trash', 'trauma', 'travel', 'traveling', 'travelling', 'treat', 'treated', 'treatment', 'trebor', 'trek', 'trekkie', 'trekkies', 'treks', 'trend', 'trial', 'trick', 'tried', 'tries', 'trill', 'trilogies', 'trilogy', 'trip', 'troi', 'troopers', 'tros', 'trouble', 'true', 'truly', 'trust', 'trusted', 'truth', 'try', 'trying', 'turn', 'turned', 'turning', 'turns', 'turret', 'tusken', 'tutso', 'tuvok', 'tv', 'tweet', 'twenty', 'twice', 'twin', 'twins', 'twist', 'twisted', 'twists', 'twitter', 'two', 'type', 'types', 'typically', 'ugh', 'ultimate', 'ultimately', 'un', 'unable', 'unaware', 'uncle', 'uncomfortable', 'underdeveloped', 'underdog', 'underlying', 'understand', 'understandable', 'understanding', 'understands', 'understood', 'underused', 'unduli', 'unexpected', 'unfair', 'unfinished', 'unfortunate', 'unfortunately', 'unification', 'uniform', 'uniforms', 'unique', 'uniqueness', 'united', 'universe', 'unknown', 'unleashed', 'unless', 'unlikable', 'unlike', 'unlikely', 'unnatural', 'unnecessary', 'unpopular', 'unrealistically', 'unreasonable', 'unresolved', 'unsure', 'update', 'upgrade', 'upgraded', 'upon', 'ups', 'upset', 'urge', 'us', 'use', 'used', 'useful', 'useless', 'user', 'users', 'uses', 'using', 'uss', 'usual', 'usually', 'utopia', 'utter', 'utterly', 'vader', 'vaders', 'vague', 'valid', 'value', 'values', 'vandermeer', 'variety', 'various', 'vash', 'vastly', 'vebb', 'vehicles', 'ventress', 'version', 'versions', 'versus', 'vessel', 'vhs', 'vi', 'via', 'vibe', 'victory', 'video', 'videos', 'vids', 'view', 'viewed', 'viewer', 'viewers', 'viewing', 'views', 'vii', 'viii', 'village', 'villain', 'villains', 'violence', 'violent', 'violently', 'virtual', 'virus', 'vision', 'visions', 'visit', 'visits', 'visual', 'visually', 'visuals', 'voice', 'voices', 'volumes', 'vong', 'vos', 'voy', 'voyager', 'vr', 'vs', 'vulcan', 'vulcans', 'wait', 'waited', 'waiting', 'wakes', 'walk', 'walked', 'walking', 'walks', 'wall', 'wan', 'wanna', 'want', 'wanted', 'wanting', 'wants', 'war', 'warm', 'warning', 'warp', 'warrior', 'warriors', 'wars', 'wasnt', 'waste', 'wasted', 'watch', 'watched', 'watchers', 'watches', 'watching', 'water', 'wave', 'way', 'ways', 'weak', 'weakened', 'weakness', 'weapon', 'weapons', 'wear', 'wearing', 'website', 'week', 'weeks', 'weight', 'weighted', 'weird', 'welcome', 'well', 'went', 'wesley', 'western', 'whale', 'whatch', 'whatched', 'whatever', 'whats', 'whenever', 'whereas', 'wherever', 'whether', 'whichever', 'whilst', 'whiskey', 'white', 'whoever', 'whole', 'whose', 'wide', 'widely', 'wife', 'wikipedia', 'wil', 'wild', 'williams', 'willing', 'win', 'wind', 'window', 'windu', 'winn', 'winning', 'wins', 'wipe', 'wiped', 'wisdom', 'wise', 'wish', 'wishes', 'within', 'without', 'witnessed', 'wizards', 'woke', 'wolf', 'woman', 'women', 'wonder', 'wondered', 'wonderful', 'wondering', 'wonders', 'wont', 'wood', 'word', 'words', 'worf', 'work', 'worked', 'working', 'works', 'world', 'worldbuilding', 'worlds', 'wormhole', 'worried', 'worry', 'worse', 'worst', 'worth', 'worthy', 'would', 'wouldve', 'wound', 'wounded', 'wounds', 'wow', 'wraiths', 'wrap', 'wrapped', 'wrenching', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrote', 'wtf', 'xbs', 'xindi', 'ya', 'yada', 'yaddle', 'yar', 'yarael', 'yeah', 'year', 'years', 'yellow', 'yes', 'yesterday', 'yet', 'yoda', 'young', 'younger', 'younglings', 'youth', 'youtube', 'yr', 'yularen', 'yuuzhan', 'zahn', 'zero', 'zett', 'zhan', 'zhat', 'ziro', 'zone', 'zoom', 'zv', 'zya']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate logistic regression model.\n",
    "lr = LogisticRegression(solver = 'liblinear')#lr = LogisticRegression(solver = 'liblinear') # lbfgs vs. liblinear\n",
    "\n",
    "# Fit model to training data.\n",
    "lr.fit(train_data_features,y_train)\n",
    "\n",
    "# Evaluate model on training data.\n",
    "lr.score(train_data_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805013927576601"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model on testing data.\n",
    "lr.score(test_data_features,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since our model has a higher accuracy on the training set than on the testing set, our model is overfit.\n",
    "#We could combat this overfitting by removing features (i.e. setting max_features to be 5000) \n",
    "#and/or by regularizing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.51532\n",
       "1    0.48468\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. LogisticRegression (estimator)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'lbfgs'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1_000,2_000,3_000,5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_params,\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [1000, 2000, 3000, 5000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9628908833254606\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model as gs_model.\n",
    "\n",
    "gs_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9721448467966574"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the transformer.\n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>00s</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>109</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>zhat</th>\n",
       "      <th>zilo</th>\n",
       "      <th>ziro</th>\n",
       "      <th>ziyal</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorii</th>\n",
       "      <th>zv</th>\n",
       "      <th>zya</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.286711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 11339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000  007  00s   09   10  100  1000  10000  109   11  ...  zhat  zilo  \\\n",
       "0  0.000000  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1  0.000000  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2  0.000000  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3  0.286711  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4  0.000000  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   ziro  ziyal  zombie  zone  zoom  zorii   zv  zya  \n",
       "0   0.0    0.0     0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "1   0.0    0.0     0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "2   0.0    0.0     0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "3   0.0    0.0     0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "4   0.0    0.0     0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 11339 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tvec.fit_transform(X_train).toarray(),\n",
    "                  columns=tvec.get_feature_names())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tvec.fit_transform(X_train)\n",
    "\n",
    "X_test = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Intercept: [-0.20019556]\n",
      "Logistic Regression Coefficient: [[ 0.03213119  0.00974824  0.0341927  ... -0.04091978  0.11873398\n",
      "   0.0567927 ]]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Instantiate our model.\n",
    "logreg= LogisticRegression()\n",
    "\n",
    "# Step 2: Fit our model.\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "print(f'Logistic Regression Intercept: {logreg.intercept_}')\n",
    "print(f'Logistic Regression Coefficient: {logreg.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.9860724233983287\n"
     ]
    }
   ],
   "source": [
    "# Instantiate logistic regression.\n",
    "lr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "# Fit logistic regression.\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate logistic regression.\n",
    "print(f'Training Score: {lr.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model is overfit as training score is greater than testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes is appropriate when our features are variables that take on only positive integer counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb= MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "predictions = nb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.9888579387186629\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Score: {nb.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {nb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184   1]\n",
      " [  3 171]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       185\n",
      "           1       0.99      0.98      0.99       174\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Accuracy score is 99%, which is better ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mnb =Pipeline([('bow',CountVectorizer()),\n",
    "                    ('tfid',TfidfTransformer()),\n",
    "               ('model',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnb= new_df['selftext']\n",
    "y_mnb= new_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mnb, X_test_mnb, y_train_mnb, y_test_mnb = train_test_split(X_mnb,\n",
    "                                                    y_mnb,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfid',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('model',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_mnb.fit(X_train_mnb,y_train_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipe_mnb.predict(X_test_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[196   1]\n",
      " [  1 161]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       197\n",
      "           1       0.99      0.99      0.99       162\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.99      0.99      0.99       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_mnb,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test_mnb,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#My second Multinomial Naive Bayes model performed the best.  \n",
    "#The accuracy score was 99.0% on training data and 98.0% on unclean data. \n",
    "#This means our model is slightly and probably inconsequentially overfit. \n",
    "#This also means that 99.0% of our posts will be accurately classified by our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
